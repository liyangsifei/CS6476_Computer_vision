{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Implement the basic stereo algorithm of taking a window around every pixel in one image and search for the best match along the same scan line in the other image. You will do this both left to right and right to left. Remember: because of depth changes (discontinuities) some pixels visible in the left image are not in the right and vice a versa. So you will match in both directions.\n",
    "\n",
    "    a) Implement the SSD match algorithm, and create a disparity image D(x,y) such that L(x,y) = R(x+D(x,y),y) when matching from left to right. Also match from right to left.\n",
    "    Output: Show DL(x,y) [matching from left to right] and DR(x,y)[matching from right to left] as images. These disparity images may need to be scaled and shifted to display correctly. They should show a central square moved 2 pixels to the left or right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1L = cv2.imread(\"./Data/leftTest.png\", cv2.COLOR_BGR2GRAY)\n",
    "img1R = cv2.imread(\"./Data/rightTest.png\", cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_SSD(img1, img2, win_size=10, offset=100, l2r=True):\n",
    "    img1_h, img1_w = img1.shape\n",
    "    ing2_h, img2_w = img2.shape\n",
    "    D = np.zeros((img1_h, img1_w))\n",
    "    for ix in range(int(win_size/2), img1_w - int(win_size/2)):\n",
    "        for iy in range(int(win_size/2), img1_h - int(win_size/2)):\n",
    "            \n",
    "            w1 = img1[iy - int(win_size/2) : iy + int(win_size/2), ix - int(win_size/2) : ix + int(win_size/2)]\n",
    "            disparity = float('inf')\n",
    "\n",
    "            for d in range(offset):\n",
    "                if l2r:\n",
    "                    w2 = img2[iy - int(win_size/2) : iy + int(win_size/2), ix - int(win_size/2) - d : ix + int(win_size/2) - d]\n",
    "                else:\n",
    "                    w2 = img2[iy - int(win_size/2) : iy + int(win_size/2), ix - int(win_size/2) + d : ix + int(win_size/2) + d]\n",
    "                if w2.shape == w1.shape:\n",
    "                    diff = np.subtract(w1, w2)\n",
    "                    diff = diff.astype(int)\n",
    "                    diff = np.power(diff, 2)\n",
    "                    disp = np.sum(diff)\n",
    "                    if disp < disparity:\n",
    "                        disparity = disp\n",
    "                        D[iy, ix] = d\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_d(D):\n",
    "    m = np.max(D)\n",
    "    return D/m * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1L = match_SSD(img1L, img1R, 10, 10, True)\n",
    "cv2.imwrite('ps2-1-a-1.png', scale_d(D1L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1R = match_SSD(img1R, img1L, 10, 10, False)\n",
    "cv2.imwrite('ps2-1-a-2.png', scale_d(D1R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Now we’re going to try this on a real image pair: proj2-pair1-L .png and proj2-pair1-R .png. Since these are color images create gray scale versions. You can use rgb2gray or your own function.\n",
    "\n",
    "    a) Again apply your SSD match algorithm, and again create a disparity image D(x,y) such that L(x,y) = R(x+DL(x,y),y) when matching from left to right. Also match from right to left. \n",
    "    Output: Show DL(x,y) [matching from left to right] and DR(x,y)[matching from right to left] as images. These disparity images may need to be scaled and shifted to display correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2L = cv2.imread(\"./Data/proj2-pair1-L.png\")\n",
    "img2R = cv2.imread(\"./Data/proj2-pair1-R.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2L = cv2.cvtColor(img2L, cv2.COLOR_BGR2GRAY)\n",
    "img2R = cv2.cvtColor(img2R, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 640)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2L = match_SSD(img2L, img2R, 10, 100, True)\n",
    "cv2.imwrite('ps2-2-a-1.png', scale_d(D2L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2R = match_SSD(img2R, img2L, 10, 100, False)\n",
    "cv2.imwrite('ps2-2-a-2.png', scale_d(D2R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b) Also in this directory are the ground truth disparity images proj2-pair1-Disp-L .png and proj2-pair1-Disp-R .png. Compare your results.\n",
    "    Output: description of the differences between your results and the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "My output has lots of noise, especially when the original image has small details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 SSD is not very robust to certain perturbations. We’re going to try to see the effect of perturbations: \n",
    "\n",
    "    a. Add some Gaussian noise to the image; either one or both. Make the noise sigma big enough that you can tell some noise has been added. Run SSD again.\n",
    "    Output: Disparity images and analysis of result compared to part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = 0\n",
    "sigma = 19\n",
    "noise = np.random.normal(mean, sigma, img2L.shape)\n",
    "img2L_noised = img2L.copy()\n",
    "img2L_noised = img2L_noised + noise\n",
    "img2L_noised = np.clip(img2L_noised, 0, 255)\n",
    "cv2.imwrite('img2_noise.png', img2L_noised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2R_noised = img2R.copy()\n",
    "img2R_noised = img2R_noised + noise\n",
    "img2R_noised = np.clip(img2R_noised, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2L_noised = match_SSD(img2L_noised, img2R, 10, 100, True)\n",
    "cv2.imwrite('ps2-3-a-1.png', scale_d(D2L_noised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2L_noised2 = match_SSD(img2L_noised, img2R_noised, 10, 100, True)\n",
    "cv2.imwrite('ps2-3-a-2.png', scale_d(D2L_noised2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2L_noised3 = match_SSD(img2L, img2R_noised, 10, 100, True)\n",
    "cv2.imwrite('ps2-3-a-3.png', scale_d(D2L_noised3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: After added noise to the left image, I found the result of disparity image looks closer to the real depth image. If there are similar patterns in an epipolar line, the disparity may be minimize in a wrong place, so we get a wrong depth image in some position. But after added noise to one image,  \n",
    "\n",
    "If add noises to both two images, there is no pixel displacement for the noises as for the objects in the image between the left and right original image. So for many patterns, they cannot find a good result. F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Instead of the Gaussian noise, increase the contrast (multiplication) of one of the images by just 10%. Run SSD again.\n",
    "    Output: Disparity images and analysis of result compared to part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2L_contrast = np.zeros((img2L.shape))\n",
    "for iy in range(img2L.shape[0]):\n",
    "    for ix in range(img2L.shape[1]):\n",
    "        if img2L[iy, ix] > 128:\n",
    "            img2L_contrast[iy, ix] = 1.1 * img2L[iy, ix]\n",
    "        else:\n",
    "            img2L_contrast[iy, ix] = 0.9 * img2L[iy, ix]\n",
    "        if img2L_contrast[iy, ix] > 255:\n",
    "            img2L_contrast[iy, ix] = 255\n",
    "        if img2L_contrast[iy, ix] < 0:\n",
    "            img2L_contrast[iy, ix] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2L_contrast = match_SSD(img2L_contrast, img2R, 10, 100, True)\n",
    "cv2.imwrite('ps2-3-b.png', scale_d(D2L_contrast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "The contrast image made the depth image less noise, its better for small details because that can make it easier to match. But areas like the plaster head, there are many similar patterns in an epipolar line, so it calculated to a wrong depth comparing with other objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Now you’re going to use (not implement yourself unless you want) an improved method, called normalized correlation – this is discussed in the book. The basic idea is that we think of two image patches as vectors and to compute the angle between them – much like normalized dot products.\n",
    "\n",
    "    a) Implement a window matching stereo algorithm using some form of normalized correlation. Test it on the original images both left to right and right to left.\n",
    "    Output: disparity images and description of how it compares to the SSD version and to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_norm(img1, img2, win_size=10, search_len=10, l2r=True):\n",
    "    img1_h, img1_w = img1.shape\n",
    "    img2_h, img2_w = img2.shape\n",
    "    img1 = img1.astype(np.uint8)\n",
    "    img2 = img2.astype(np.uint8)\n",
    "    D = np.zeros((img1_h, img1_w))\n",
    "    for ix in range(int(win_size/2), img1_w - int(win_size/2)):\n",
    "        for iy in range(int(win_size/2), img1_h - int(win_size/2)):\n",
    "            \n",
    "            w1 = img1[iy - int(win_size/2) : iy + int(win_size/2), ix - int(win_size/2) : ix + int(win_size/2)]\n",
    "            disparity = float('inf')\n",
    "            #w1 = w1.astype(np.uint8)\n",
    "            for d in range(search_len):\n",
    "                if l2r:\n",
    "                    w2 = img2[iy - int(win_size/2) : iy + int(win_size/2), ix - int(win_size/2) - d : ix + int(win_size/2) - d]\n",
    "                else:\n",
    "                    w2 = img2[iy - int(win_size/2) : iy + int(win_size/2), ix - int(win_size/2) + d : ix + int(win_size/2) + d]\n",
    "                \n",
    "                # w2 = w2.astype(np.uint8)\n",
    "                if w2.shape == w1.shape:\n",
    "                    disp = cv2.matchTemplate(w1, w2, method=cv2.TM_CCOEFF_NORMED)\n",
    "                    if disp < disparity:\n",
    "                        disparity = disp\n",
    "                        D[iy, ix] = d\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2nL = match_norm(img2L, img2R, 20, 100, True)\n",
    "cv2.imwrite('ps2-4-a-1.png', scale_d(D2nL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2nR = match_norm(img2R, img2L, 20, 100, False)\n",
    "cv2.imwrite('ps2-4-a-2.png', scale_d(D2nR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b) Now test it on both the Gaussian noise and contrast boosted versions from 2a and 2b. Output: Again disparity images and analysis of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511, 640)\n",
      "(511, 640)\n"
     ]
    }
   ],
   "source": [
    "print(img2L_noised.shape)\n",
    "print(img2R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2nL_noised = match_norm(img2L_noised, img2R, 10, 100, True)\n",
    "cv2.imwrite('ps2-4-b-1.png', scale_d(D2nL_noised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2nL_contrast = match_norm(img2L_contrast, img2R, 10, 100, True)\n",
    "cv2.imwrite('ps2-4-b-2.png', scale_d(D2nL_contrast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Finally, there is a second pair of images: proj2-pair2-L .png and proj2-pair2-R .png\n",
    "\n",
    "    a. Try your algorithms on this pair. Play with the images – smooth, sharpen, etc. Keep comparing to the ground truth.\n",
    "    Output: disparity images and analysis of what it takes to make stereo work using a window based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3L = cv2.imread(\"./Data/proj2-pair2-L.png\")\n",
    "img3R = cv2.imread(\"./Data/proj2-pair2-R.png\")\n",
    "img3L = cv2.cvtColor(img3L, cv2.COLOR_BGR2GRAY)\n",
    "img3R = cv2.cvtColor(img3R, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3L = match_SSD(img3L, img3R, 10, 100, True)\n",
    "cv2.imwrite('ps2-5-a-1.png', scale_d(D3L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3L_blur = cv2.GaussianBlur(img3L, (11, 11), 9)\n",
    "# img3L_sharpened = cv2.GaussianBlur()\n",
    "cv2.imwrite(\"img3_blur.png\", img3L_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3L_blur = match_SSD(img3L_blur, img3R, 10, 100, True)\n",
    "cv2.imwrite('ps2-5-a-2.png', scale_d(D3L_blur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
